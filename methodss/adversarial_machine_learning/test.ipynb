{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load the data and first test the base line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/milad/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# import load_iris function from datasets module\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 5.1  3.5  1.4  0.2]\n",
      " [ 4.9  3.   1.4  0.2]\n",
      " [ 4.7  3.2  1.3  0.2]\n",
      " [ 4.6  3.1  1.5  0.2]\n",
      " [ 5.   3.6  1.4  0.2]\n",
      " [ 5.4  3.9  1.7  0.4]\n",
      " [ 4.6  3.4  1.4  0.3]\n",
      " [ 5.   3.4  1.5  0.2]\n",
      " [ 4.4  2.9  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.4  3.7  1.5  0.2]\n",
      " [ 4.8  3.4  1.6  0.2]\n",
      " [ 4.8  3.   1.4  0.1]\n",
      " [ 4.3  3.   1.1  0.1]\n",
      " [ 5.8  4.   1.2  0.2]\n",
      " [ 5.7  4.4  1.5  0.4]\n",
      " [ 5.4  3.9  1.3  0.4]\n",
      " [ 5.1  3.5  1.4  0.3]\n",
      " [ 5.7  3.8  1.7  0.3]\n",
      " [ 5.1  3.8  1.5  0.3]\n",
      " [ 5.4  3.4  1.7  0.2]\n",
      " [ 5.1  3.7  1.5  0.4]\n",
      " [ 4.6  3.6  1.   0.2]\n",
      " [ 5.1  3.3  1.7  0.5]\n",
      " [ 4.8  3.4  1.9  0.2]\n",
      " [ 5.   3.   1.6  0.2]\n",
      " [ 5.   3.4  1.6  0.4]\n",
      " [ 5.2  3.5  1.5  0.2]\n",
      " [ 5.2  3.4  1.4  0.2]\n",
      " [ 4.7  3.2  1.6  0.2]\n",
      " [ 4.8  3.1  1.6  0.2]\n",
      " [ 5.4  3.4  1.5  0.4]\n",
      " [ 5.2  4.1  1.5  0.1]\n",
      " [ 5.5  4.2  1.4  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 5.   3.2  1.2  0.2]\n",
      " [ 5.5  3.5  1.3  0.2]\n",
      " [ 4.9  3.1  1.5  0.1]\n",
      " [ 4.4  3.   1.3  0.2]\n",
      " [ 5.1  3.4  1.5  0.2]\n",
      " [ 5.   3.5  1.3  0.3]\n",
      " [ 4.5  2.3  1.3  0.3]\n",
      " [ 4.4  3.2  1.3  0.2]\n",
      " [ 5.   3.5  1.6  0.6]\n",
      " [ 5.1  3.8  1.9  0.4]\n",
      " [ 4.8  3.   1.4  0.3]\n",
      " [ 5.1  3.8  1.6  0.2]\n",
      " [ 4.6  3.2  1.4  0.2]\n",
      " [ 5.3  3.7  1.5  0.2]\n",
      " [ 5.   3.3  1.4  0.2]\n",
      " [ 7.   3.2  4.7  1.4]\n",
      " [ 6.4  3.2  4.5  1.5]\n",
      " [ 6.9  3.1  4.9  1.5]\n",
      " [ 5.5  2.3  4.   1.3]\n",
      " [ 6.5  2.8  4.6  1.5]\n",
      " [ 5.7  2.8  4.5  1.3]\n",
      " [ 6.3  3.3  4.7  1.6]\n",
      " [ 4.9  2.4  3.3  1. ]\n",
      " [ 6.6  2.9  4.6  1.3]\n",
      " [ 5.2  2.7  3.9  1.4]\n",
      " [ 5.   2.   3.5  1. ]\n",
      " [ 5.9  3.   4.2  1.5]\n",
      " [ 6.   2.2  4.   1. ]\n",
      " [ 6.1  2.9  4.7  1.4]\n",
      " [ 5.6  2.9  3.6  1.3]\n",
      " [ 6.7  3.1  4.4  1.4]\n",
      " [ 5.6  3.   4.5  1.5]\n",
      " [ 5.8  2.7  4.1  1. ]\n",
      " [ 6.2  2.2  4.5  1.5]\n",
      " [ 5.6  2.5  3.9  1.1]\n",
      " [ 5.9  3.2  4.8  1.8]\n",
      " [ 6.1  2.8  4.   1.3]\n",
      " [ 6.3  2.5  4.9  1.5]\n",
      " [ 6.1  2.8  4.7  1.2]\n",
      " [ 6.4  2.9  4.3  1.3]\n",
      " [ 6.6  3.   4.4  1.4]\n",
      " [ 6.8  2.8  4.8  1.4]\n",
      " [ 6.7  3.   5.   1.7]\n",
      " [ 6.   2.9  4.5  1.5]\n",
      " [ 5.7  2.6  3.5  1. ]\n",
      " [ 5.5  2.4  3.8  1.1]\n",
      " [ 5.5  2.4  3.7  1. ]\n",
      " [ 5.8  2.7  3.9  1.2]\n",
      " [ 6.   2.7  5.1  1.6]\n",
      " [ 5.4  3.   4.5  1.5]\n",
      " [ 6.   3.4  4.5  1.6]\n",
      " [ 6.7  3.1  4.7  1.5]\n",
      " [ 6.3  2.3  4.4  1.3]\n",
      " [ 5.6  3.   4.1  1.3]\n",
      " [ 5.5  2.5  4.   1.3]\n",
      " [ 5.5  2.6  4.4  1.2]\n",
      " [ 6.1  3.   4.6  1.4]\n",
      " [ 5.8  2.6  4.   1.2]\n",
      " [ 5.   2.3  3.3  1. ]\n",
      " [ 5.6  2.7  4.2  1.3]\n",
      " [ 5.7  3.   4.2  1.2]\n",
      " [ 5.7  2.9  4.2  1.3]\n",
      " [ 6.2  2.9  4.3  1.3]\n",
      " [ 5.1  2.5  3.   1.1]\n",
      " [ 5.7  2.8  4.1  1.3]\n",
      " [ 6.3  3.3  6.   2.5]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 7.1  3.   5.9  2.1]\n",
      " [ 6.3  2.9  5.6  1.8]\n",
      " [ 6.5  3.   5.8  2.2]\n",
      " [ 7.6  3.   6.6  2.1]\n",
      " [ 4.9  2.5  4.5  1.7]\n",
      " [ 7.3  2.9  6.3  1.8]\n",
      " [ 6.7  2.5  5.8  1.8]\n",
      " [ 7.2  3.6  6.1  2.5]\n",
      " [ 6.5  3.2  5.1  2. ]\n",
      " [ 6.4  2.7  5.3  1.9]\n",
      " [ 6.8  3.   5.5  2.1]\n",
      " [ 5.7  2.5  5.   2. ]\n",
      " [ 5.8  2.8  5.1  2.4]\n",
      " [ 6.4  3.2  5.3  2.3]\n",
      " [ 6.5  3.   5.5  1.8]\n",
      " [ 7.7  3.8  6.7  2.2]\n",
      " [ 7.7  2.6  6.9  2.3]\n",
      " [ 6.   2.2  5.   1.5]\n",
      " [ 6.9  3.2  5.7  2.3]\n",
      " [ 5.6  2.8  4.9  2. ]\n",
      " [ 7.7  2.8  6.7  2. ]\n",
      " [ 6.3  2.7  4.9  1.8]\n",
      " [ 6.7  3.3  5.7  2.1]\n",
      " [ 7.2  3.2  6.   1.8]\n",
      " [ 6.2  2.8  4.8  1.8]\n",
      " [ 6.1  3.   4.9  1.8]\n",
      " [ 6.4  2.8  5.6  2.1]\n",
      " [ 7.2  3.   5.8  1.6]\n",
      " [ 7.4  2.8  6.1  1.9]\n",
      " [ 7.9  3.8  6.4  2. ]\n",
      " [ 6.4  2.8  5.6  2.2]\n",
      " [ 6.3  2.8  5.1  1.5]\n",
      " [ 6.1  2.6  5.6  1.4]\n",
      " [ 7.7  3.   6.1  2.3]\n",
      " [ 6.3  3.4  5.6  2.4]\n",
      " [ 6.4  3.1  5.5  1.8]\n",
      " [ 6.   3.   4.8  1.8]\n",
      " [ 6.9  3.1  5.4  2.1]\n",
      " [ 6.7  3.1  5.6  2.4]\n",
      " [ 6.9  3.1  5.1  2.3]\n",
      " [ 5.8  2.7  5.1  1.9]\n",
      " [ 6.8  3.2  5.9  2.3]\n",
      " [ 6.7  3.3  5.7  2.5]\n",
      " [ 6.7  3.   5.2  2.3]\n",
      " [ 6.3  2.5  5.   1.9]\n",
      " [ 6.5  3.   5.2  2. ]\n",
      " [ 6.2  3.4  5.4  2.3]\n",
      " [ 5.9  3.   5.1  1.8]]\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# save \"bunch\" object containing iris dataset and its attributes\n",
    "iris = load_iris()\n",
    "type(iris)\n",
    "\n",
    "# print the iris data\n",
    "print(iris.data)\n",
    "\n",
    "\n",
    "# print the iris data\n",
    "# print(iris.data)\n",
    "\n",
    "\n",
    "# print the names of the four features\n",
    "print(iris.feature_names)\n",
    "\n",
    "\n",
    "# print integers representing the species of each observation# print \n",
    "print(iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "# print the encoding scheme for species: 0 = setosa, 1 = versicolor, 2 = virginica\n",
    "print(iris.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store feature matrix in \"X\"# store  \n",
    "X = iris.data\n",
    "\n",
    "# store response vector in \"y\"\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb = MultinomialNB()\n",
    "mnb.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# result of the model  on test data (First step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 on test data is       0.8095238095238096\n",
      "Accuracy on test data is 0.8666666666666667\n"
     ]
    }
   ],
   "source": [
    "#compute the f1 and accuracy\n",
    "\n",
    "y_pred=mnb.predict(x_test)\n",
    "\n",
    "print (\"f1 on test data is       {}\".format(f1_score(y_test, y_pred, average='macro')))\n",
    "print (\"Accuracy on test data is {}\".format(accuracy_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[16,  0,  0],\n",
       "       [ 0,  5,  0],\n",
       "       [ 0,  4,  5]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# result model on the same train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 on same train data is       0.8777540867093107\n",
      "Accuracy on same train data is 0.875\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00        34\n",
      "          1       0.75      1.00      0.86        45\n",
      "          2       1.00      0.63      0.78        41\n",
      "\n",
      "avg / total       0.91      0.88      0.87       120\n",
      "\n",
      "[[34  0  0]\n",
      " [ 0 45  0]\n",
      " [ 0 15 26]]\n"
     ]
    }
   ],
   "source": [
    "y_pred_train=mnb.predict(x_train)\n",
    "\n",
    "\n",
    "print (\"f1 on same train data is       {}\".format(f1_score(y_train, y_pred_train, average='macro')))\n",
    "print (\"Accuracy on same train data is {}\".format(accuracy_score(y_train, y_pred_train)))\n",
    "print(\"\\n\" + classification_report(y_train, y_pred_train))\n",
    "\n",
    "\n",
    "print(confusion_matrix(y_train, y_pred_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# base line\n",
    "- change one feature and chek the target (change function)\n",
    "- change randomly one value and check the target(change random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_plan={\"key\":[[0,1],[2,1]],\"number\":[3,3]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_baseline(x_train,y_train,percetage,mnb,change_plan):\n",
    "    number_change = int(percetage/100*x_train.shape[0])\n",
    "    \n",
    "    x_train_changed = np.copy(x_train)\n",
    "    row_history=[]\n",
    "    try_times = 0\n",
    "    occurred_change=0\n",
    "    change_done = False\n",
    "    \n",
    "        \n",
    "    for i in range(len(change_plan[\"number\"])):\n",
    "        for j in range(change_plan[\"number\"][i]):\n",
    "\n",
    "            change_done = False\n",
    "            while (change_done == False):\n",
    "\n",
    "                #find uniqe row & as same as user request \n",
    "                row = random.randint(1, x_train.shape[0]-1)\n",
    "                try_times = 0\n",
    "                while (mnb.predict([x_train[row]])[0] !=change_plan[\"key\"][i][0] or row in row_history): #row in row_history or\n",
    "\n",
    "                    row = random.randint(1, x_train.shape[0]-1)\n",
    "                    if try_times > len(y_train):\n",
    "                        print(\"your request is not possiable\")\n",
    "                        break \n",
    "                        \n",
    "                    try_times = try_times + 1\n",
    "                if try_times > len(y_train):\n",
    "                    print(\"part of your request can't run\")\n",
    "                    break\n",
    "                    \n",
    "                row_history.append(row)\n",
    "\n",
    "                for ii in range(x_train.shape[1]): # range(4)\n",
    "                    x_train_changed[row][ii] = 0\n",
    "\n",
    "                    if (change_plan[\"key\"][i][1] == mnb.predict([x_train_changed[row]])):\n",
    "                        print(x_train[row],mnb.predict([x_train[row]])[0])\n",
    "                        print(x_train_changed[row],mnb.predict([x_train_changed[row]])[0])\n",
    "                        occurred_change=occurred_change + 1\n",
    "                        change_done = True\n",
    "                        print(\" \\n change number {} \\n\".format(occurred_change))\n",
    "                        break\n",
    "                    else:\n",
    "#                         print(\"this change doesnot run\")\n",
    "                        x_train_changed[row]= np.copy(x_train[row])\n",
    "                \n",
    "\n",
    "\n",
    "    return np.copy(x_train_changed)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 4.8  3.4  1.6  0.2] 0\n",
      "[ 4.8  0.   1.6  0.2] 1\n",
      " \n",
      " change number 1 \n",
      "\n",
      "[ 4.5  2.3  1.3  0.3] 0\n",
      "[ 0.   2.3  1.3  0.3] 1\n",
      " \n",
      " change number 2 \n",
      "\n",
      "[ 5.1  3.8  1.5  0.3] 0\n",
      "[ 5.1  0.   1.5  0.3] 1\n",
      " \n",
      " change number 3 \n",
      "\n",
      "[ 7.6  3.   6.6  2.1] 2\n",
      "[ 7.6  3.   6.6  0. ] 1\n",
      " \n",
      " change number 4 \n",
      "\n",
      "[ 6.7  3.3  5.7  2.1] 2\n",
      "[ 6.7  3.3  5.7  0. ] 1\n",
      " \n",
      " change number 5 \n",
      "\n",
      "[ 5.8  2.7  5.1  1.9] 2\n",
      "[ 5.8  2.7  0.   1.9] 1\n",
      " \n",
      " change number 6 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "baseline_out=change_baseline(x_test,y_test,20,mnb,change_plan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 on same train data is       0.5867293625914315\n",
      "Accuracy on test data is 0.6666666666666666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[13,  3,  0],\n",
       "       [ 0,  5,  0],\n",
       "       [ 0,  7,  2]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_baseline_changed=mnb.predict(baseline_out)\n",
    "\n",
    "\n",
    "print (\"f1 on same train data is       {}\".format(f1_score(y_test, y_pred_baseline_changed, average='macro')))\n",
    "print (\"Accuracy on test data is {}\".format(accuracy_score(y_test, y_pred_baseline_changed)))\n",
    "confusion_matrix(y_test,y_pred_baseline_changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change(x_train,y_train,percetage,mnb):\n",
    "    \n",
    "    number_change = int(percetage/100*x_train.shape[0])\n",
    "    print(number_change)\n",
    "    \n",
    "    x_train_changed = np.copy(x_train)\n",
    "\n",
    "    for count,ele in enumerate(x_train_changed[:number_change+2]):\n",
    "        print(x_train[count],y_train[count])\n",
    "        for i in range(4):\n",
    "            x_train_changed[count][i] = 0\n",
    "\n",
    "            if (y_train[count] != mnb.predict([x_train_changed[count]])):\n",
    "                break\n",
    "            else:\n",
    "                x_train_changed[count]= np.copy(x_train[count])\n",
    "\n",
    "        print(x_train_changed[count],mnb.predict([x_train_changed[count]])[0])\n",
    "        print(\" \\n change number {} \\n\".format(count))\n",
    "\n",
    "    return np.copy(x_train_changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new=change(x_train,y_train,20.8,mnb)\n",
    "new=change(x_test,y_test,20,mnb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# result model on the dirty data (10 %)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_changed=mnb.predict(new)\n",
    "\n",
    "\n",
    "# print (\"f1 on same train data is       {}\".format(f1_score(y_train, y_pred_train_changed, average='macro')))\n",
    "# print (\"Accuracy on same train data is {}\".format(accuracy_score(y_train, y_pred_train_changed)))\n",
    "\n",
    "\n",
    "print (\"f1 on same train data is       {}\".format(f1_score(y_test, y_pred_train_changed, average='macro')))\n",
    "print (\"Accuracy on test data is {}\".format(accuracy_score(y_test, y_pred_train_changed)))\n",
    "confusion_matrix(y_test, y_pred_train_changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_plan={\"key\":[[0,1],[2,1]],\"number\":[3,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_random(x_train,y_train,percetage,mnb,change_plan):\n",
    "    number_change_requested = int(percetage/100*x_train.shape[0])\n",
    "    \n",
    "    print(\"{} percentage error is equal to {} change \\n\".format(percetage,number_change_requested))\n",
    "    \n",
    "    row_history=[]\n",
    "    col_history=[]\n",
    "    occurred_change=0\n",
    "    \n",
    "    x_train_changed = np.copy(x_train)\n",
    "    \n",
    "            \n",
    "    for i in range(len(change_plan[\"number\"])):\n",
    "        for j in range(change_plan[\"number\"][i]):\n",
    "\n",
    "            change_done = False\n",
    "            while (change_done == False):\n",
    "\n",
    "                #find uniqe row & as same as user request \n",
    "                row = random.randint(1, x_train.shape[0]-1)\n",
    "                try_times = 0\n",
    "                while (mnb.predict([x_train[row]])[0] !=change_plan[\"key\"][i][0] or row in row_history): #row in row_history or\n",
    "\n",
    "                    row = random.randint(1, x_train.shape[0]-1)\n",
    "                    if try_times > len(y_train):\n",
    "                        print(\"your request is not possiable\")\n",
    "                        break \n",
    "                        \n",
    "                    try_times = try_times + 1\n",
    "                if try_times > len(y_train):\n",
    "                    print(\"part of your request can't run\")\n",
    "                    break\n",
    "                    \n",
    "                row_history.append(row)\n",
    "                \n",
    "                \n",
    "                while (len(col_history)<=x_train.shape[1]+1):\n",
    "                    \n",
    "                    col = random.randint(0,x_train.shape[1]-1)\n",
    "                    while col in col_history:\n",
    "                        col = random.randint(0,x_train.shape[1]-1)\n",
    "                        if (len(col_history)<=x_train.shape[1]+1):\n",
    "                            break\n",
    "                    col_history.append(col)\n",
    "                    x_train_changed[row][col] = 0\n",
    "                    \n",
    "                    if (change_plan[\"key\"][i][1] == mnb.predict([x_train_changed[row]])):\n",
    "                        print(x_train[row],mnb.predict([x_train[row]])[0])\n",
    "                        print(x_train_changed[row],mnb.predict([x_train_changed[row]])[0])\n",
    "                        occurred_change=occurred_change + 1\n",
    "                        change_done = True\n",
    "                        print(\" \\n change number {} \\n\".format(occurred_change))\n",
    "                        break\n",
    "                    else:\n",
    "                        x_train_changed[row]= np.copy(x_train[row])\n",
    "\n",
    "\n",
    "    return np.copy(x_train_changed)\n",
    "         \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 percentage error is equal to 6 change \n",
      "\n",
      "[ 4.8  3.4  1.9  0.2] 0\n",
      "[ 4.8  0.   1.9  0.2] 1\n",
      " \n",
      " change number 1 \n",
      "\n",
      "your request is not possiable\n",
      "part of your request can't run\n",
      "your request is not possiable\n",
      "part of your request can't run\n",
      "your request is not possiable\n",
      "part of your request can't run\n",
      "your request is not possiable\n",
      "part of your request can't run\n",
      "your request is not possiable\n",
      "part of your request can't run\n"
     ]
    }
   ],
   "source": [
    "new_random=change_random(x_test,y_test,20,mnb,change_plan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# result model on the dirty data (10 %) -random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 on same train data is       0.6506238859180036\n",
      "Accuracy on same train data is 0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "y_pred_test_changed_random=mnb.predict(new_random)\n",
    "\n",
    "\n",
    "# print (\"f1 on same train data is       {}\".format(f1_score(y_train, y_pred_train_changed_random, average='macro')))\n",
    "# print (\"Accuracy on same train data is {}\".format(accuracy_score(y_train, y_pred_train_changed_random)))\n",
    "\n",
    "\n",
    "print (\"f1 on same train data is       {}\".format(f1_score(y_test, y_pred_test_changed_random, average='macro')))\n",
    "print (\"Accuracy on same train data is {}\".format(accuracy_score(y_test, y_pred_test_changed_random)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test,y_pred_test_changed_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find the most important features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn = KNeighborsClassifier(n_neighbors=4)\n",
    "mnb2 = MultinomialNB()\n",
    "# sfs1 = SFS(knn, \n",
    "#            k_features=1, \n",
    "#            forward=True, \n",
    "#            floating=False, \n",
    "#            verbose=2,\n",
    "#            scoring='accuracy',\n",
    "#            cv=0)\n",
    "sfs1 = SFS(mnb, \n",
    "#            k_features=1, \n",
    "           forward=True, \n",
    "           floating=False, \n",
    "           verbose=2,\n",
    "           scoring='accuracy',\n",
    "           cv=0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sfs1 = sfs1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs1.subsets_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# most important feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs1.k_feature_idx_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_spetial_feature(x_train,y_train,percetage,mnb,feature):\n",
    "    change_item=0\n",
    "    number_change_spetial = int(percetage/100*x_train.shape[0])\n",
    "    print(number_change_spetial)\n",
    "    \n",
    "    x_train_changed_spetial = np.copy(x_train)\n",
    "\n",
    "    for count,ele in enumerate(x_train_changed_spetial):\n",
    "        \n",
    "\n",
    "        x_train_changed_spetial[count][feature] = 0\n",
    "\n",
    "        if (y_train[count] != mnb.predict([x_train_changed_spetial[count]])):\n",
    "            change_item=change_item+1\n",
    "            if (change_item < number_change_spetial):\n",
    "\n",
    "                print(x_train[count],y_train[count])\n",
    "                print(x_train_changed_spetial[count],mnb.predict([x_train_changed_spetial[count]])[0])\n",
    "                print(\" \\n change number {} \\n\".format(change_item))\n",
    "            else:\n",
    "\n",
    "                break\n",
    "        else:\n",
    "            x_train_changed_spetial[count]= np.copy(x_train[count])\n",
    "\n",
    "    return np.copy(x_train_changed_spetial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_random_spetial=change_spetial_feature(x_test,y_test,20,mnb,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# result model on the dirty data (10 %) -spetial feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train_changed_spetial=mnb.predict(new_random_spetial)\n",
    "\n",
    "\n",
    "# print (\"f1 on same train data is       {}\".format(f1_score(y_train, y_pred_train_changed_spetial, average='macro')))\n",
    "# print (\"Accuracy on same train data is {}\".format(accuracy_score(y_train, y_pred_train_changed_spetial)))\n",
    "\n",
    "print (\"f1 on same train data is       {}\".format(f1_score(y_test, y_pred_train_changed_spetial, average='macro')))\n",
    "print (\"Accuracy on same train data is {}\".format(accuracy_score(y_test, y_pred_train_changed_spetial)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co=0\n",
    "for count1,ele1 in enumerate(new_random_spetial):\n",
    "    if ele1[0]==0:\n",
    "        co=co+1\n",
    "        print(new_random_spetial[count1])\n",
    "print(co)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_indices(arr, k):\n",
    "    '''\n",
    "    Returns the indices of the k first largest elements of arr\n",
    "    (in descending order in values)\n",
    "    '''\n",
    "    assert k <= arr.size, 'k should be smaller or equal to the array size'\n",
    "    arr_ = arr.astype(float)  # make a copy of arr\n",
    "    max_idxs = []\n",
    "    for _ in range(k):\n",
    "        max_element = np.max(arr_)\n",
    "        if np.isinf(max_element):\n",
    "            break\n",
    "        else:\n",
    "            idx = np.where(arr_ == max_element)\n",
    "        max_idxs.append([int(idx[0]),int(idx[1])])\n",
    "        arr_[idx] = -np.inf\n",
    "    return max_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=confusion_matrix(y_train, y_pred_train)\n",
    "max_indices(array,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def change_confuation_matrix(x_train,mnb):\n",
    "    y_pred_train=mnb.predict(x_train)\n",
    "    array=confusion_matrix(y_train, y_pred_train)\n",
    "    \n",
    "    max_list = max_indices(array,4)\n",
    "    rong_class= max_list[array.shape[0]]\n",
    "     \n",
    "    \n",
    "    print(\"the data point of class {} wrongly classify as class {}\".format(rong_class[0],rong_class[1]))\n",
    "    df_cm = pd.DataFrame(array, range(array.shape[0]),range(array.shape[0]))\n",
    "    \n",
    "    sn.set(font_scale=1.4)#for label size\n",
    "    sn.heatmap(df_cm, annot=True,annot_kws={\"size\": 16})# font size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "change_confuation_matrix(x_train,mnb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array=confusion_matrix(y_train, y_pred_train)\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    plt.figure()\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "class_names = iris.target_names\n",
    "plot_confusion_matrix(array, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure()\n",
    "plot_confusion_matrix(array, classes=class_names, normalize=True,\n",
    "                      title='Normalized confusion matrix')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
